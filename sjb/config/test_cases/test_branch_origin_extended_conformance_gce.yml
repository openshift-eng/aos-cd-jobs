---
parent: 'common/test_cases/origin.yml'
overrides:
  junit_analysis: False
extensions:
  sync_repos:
    - name: "release"
  parameters:
    - name: "SUITE"
      description: "Which shell file in the <a href='https://github.com/openshift/origin/tree/master/test/extended'><code>origin/test/extended/</code></a> di
rectory to run."
      default_value: "conformance"
    - name: "FOCUS"
      description: "Literal string to pass to <code>--ginkgo.focus</code>"
    - name: "DOCKER_STORAGE_DRIVER"
      description: >
        The storage driver to use when configuring the cluster. 'overlay2' and 'devicemapper' are allowed.
      default_value: "overlay2"
    - name: "OPENSHIFT_ANSIBLE_IMAGE"
      description: >
        The image to install the cluster with. If set, defaults to the value defined by the
        <a href='https://github.com/openshift/release/blob/master/cluster/bin/local.sh'><code>cluster/bin/local.sh</code></a>
        script.
    - name: "ADDITIONAL_SKIP"
      description: |-
        Regular expression to filter additional tests from the conformance suite.
        See also:
        <div>
        <a style="display: block" href='https://github.com/openshift/origin/issues/12361'><code>origin</code> issue 12361</a></br>
        <a style="display: block" href='https://github.com/openshift/origin/issues/12362'><code>origin</code> issue 12362</a></br>
        <a style="display: block" href='https://github.com/openshift/origin/issues/12629'><code>origin</code> issue 12629</a></br>
        <a style="display: block" href='https://github.com/openshift/origin/issues/11016'><code>origin</code> issue 11016</a></br>
        <a style="display: block" href='https://github.com/openshift/origin/issues/12072'><code>origin</code> issue 12072</a></br>
        </div>
      default_value: '|should support subPath|should work with TCP \(when fully idled\)|should test kubelet managed /etc/hosts file|\[networking\]\[router\]|Downward API volume should update annotations on modification|should run a deployment to completion and then scale to zero|Probing container should \*not\* be restarted with a /healthz http liveness probe'
  actions:
    - type: "forward_parameters"
      parameters:
        - OPENSHIFT_ANSIBLE_IMAGE
        - ADDITIONAL_SKIP
        - JOB_NAME
        - BUILD_NUMBER
        - DOCKER_STORAGE_DRIVER
        - SUITE
        - FOCUS
    - type: "script"
      title: "build origin RPMs"
      repository: "origin"
      timeout: 2400
      script: |-
        OS_BUILD_ENV_PULL_IMAGE=true OS_BUILD_ENV_DOCKER_ARGS="-e OS_VERSION_FILE= " OS_BUILD_ENV_PRESERVE="_output/local/releases/rpms:_output/local/bin" hack/env make build-rpms BUILD_TESTS=1
    - type: "host_script"
      title: "move RPMs to GCS repo"
      script: |-
        pull_id="${ORIGIN_PULL_ID:-}"
        target_branch="${ORIGIN_TARGET_BRANCH:-}"
        if [[ -z "${pull_id}" && -n "${PULL_NUMBER:-}" ]]; then
          pull_id=${PULL_NUMBER}
          target_branch="${PULL_REFS%%:*}"
        fi
        # pull_id will be 0 in case of a batch merge
        if [[ -n "${pull_id:-}" && "${pull_id:-}" != "0" ]]; then
          location_base="origin-ci-test/pr-logs/pull/${pull_id}/${JOB_NAME}/${BUILD_NUMBER}"
          location="${location_base}/artifacts/rpms"
        else
          location_root="origin-ci-test/branch-logs/origin/${target_branch}/builds"
          location_base="${location_root}/${BUILD_NUMBER}"
          location="${location_base}/artifacts/rpms"
          base_location_url="https://storage.googleapis.com/${location_base}"
        fi
        location_url="https://storage.googleapis.com/${location}"
        echo "${JOB_NAME}/${BUILD_NUMBER}" > .build
        if gsutil ls "gs://${location_base}" &>/dev/null; then
          gsutil rm -rf "gs://${location_base}"
        fi
        gsutil cp .build "gs://${location_base}/.build"

        mkdir -p artifacts/rpms
        rsync --archive --omit-dir-times --rsh "ssh -F ./.config/origin-ci-tool/inventory/.ssh_config" --rsync-path='sudo rsync' openshiftdevel:/data/src/github.com/openshift/origin/_output/local/releases/rpms ./artifacts/ || true
        gsutil -m cp -r artifacts/rpms "gs://${location}"
        # pull_id will be 0 in case of a batch merge
        if [[ -n "${pull_id:-}" && "${pull_id:-}" != "0" ]]; then
          # if we've built this PR before, remove older rpm artifact directories
          out="$( gsutil ls -d "gs://origin-ci-test/pr-logs/pull/${pull_id}/${JOB_NAME}/*/artifacts/rpms" | sort -n -t / -k 7 | head -n -2 )"
          if [[ -n "${out}" ]]; then
            echo "${out}" | xargs -L 1 gsutil rm -rf
          fi
        else
          # update the pointer to this location
          echo "${base_location_url}" > .latest
          gsutil cp .latest "gs://${location_root}/.latest"
        fi

        # hack around forwarding this to the other machine
        ssh -F ./.config/origin-ci-tool/inventory/.ssh_config openshiftdevel "echo 'location_url=${location_url:-}' >> /etc/environment"
    - type: "host_script"
      title: "move secrets to remote host"
      script: |-
        rsync --copy-links --omit-dir-times --archive --rsh "ssh -F ./.config/origin-ci-tool/inventory/.ssh_config" /var/lib/jenkins/.gce/* openshiftdevel:/data/src/github.com/openshift/release/cluster/test-deploy/data/
        ssh -F ./.config/origin-ci-tool/inventory/.ssh_config openshiftdevel 'sudo chown -R origin:origin-git /data/src/github.com/openshift/release/cluster/test-deploy/data/'
        ssh -F ./.config/origin-ci-tool/inventory/.ssh_config openshiftdevel 'sudo chmod -R ug+rwX /data/src/github.com/openshift/release/cluster/test-deploy/data/'
    - type: "host_script"
      title: "determine the instance prefix"
      script: |-
        # we need a short but unique identifier, so we take the first 7 of SHA
        hashed_identifier="$( echo "${JOB_NAME}" | sha1sum )"
        export INSTANCE_PREFIX="prtest-${hashed_identifier:0:7}-${BUILD_NUMBER}"
        echo "INSTANCE_PREFIX=${INSTANCE_PREFIX:-}" >> INSTANCE_PREFIX
        # hack around forwarding this to the other machine
        ssh -F ./.config/origin-ci-tool/inventory/.ssh_config openshiftdevel "echo 'INSTANCE_PREFIX=${INSTANCE_PREFIX:-}' >> /etc/environment"
    - type: "script"
      title: "provision test cluster"
      repository: "release"
      timeout: 2800
      script: |-
        sudo systemctl restart docker
        cd cluster/test-deploy/data/
        if [[ -n "${OPENSHIFT_ANSIBLE_IMAGE}" ]]; then
          docker pull "${OPENSHIFT_ANSIBLE_IMAGE}"
          docker tag "${OPENSHIFT_ANSIBLE_IMAGE}" "openshift/origin-gce:latest"
        else
          docker pull openshift/origin-gce:latest
        fi

        ../../bin/local.sh ansible-playbook -e "provision_gce_docker_storage_driver=${DOCKER_STORAGE_DRIVER}" -e "openshift_test_repo=${location_url}" playbooks/launch.yaml
        cp admin.kubeconfig /tmp/cluster-admin.kubeconfig
    - type: "script"
      title: "run extended tests"
      repository: "origin"
      timeout: 4000
      script: |-
        mkdir -p /tmp/artifacts/junit
        export KUBECONFIG=/tmp/cluster-admin.kubeconfig
        export PARALLEL_NODES=25
        export EXTENDED_TEST_PATH=test/extended
        export TEST_ONLY=1
        export JUNIT_REPORT=true
        export TEST_EXTENDED_SKIP="\[local\]"
        TEST_EXTENDED_SKIP+="${ADDITIONAL_SKIP-}"
        export GOOGLE_APPLICATION_CREDENTIALS="/data/src/github.com/openshift/release/cluster/test-deploy/data/gce.json"
        export TEST_EXTENDED_ARGS='-provider=gce -gce-zone=us-central1-a -gce-project=openshift-gce-devel-ci'

        function gather() {
          set +e
          OS_BUILD_ENV_PULL_IMAGE=true OS_BUILD_ENV_PRESERVE=_output/local/bin/linux/amd64/oc hack/env make build WHAT=cmd/oc
          export PATH=$(pwd)/_output/local/bin/linux/amd64:$PATH
          oc get nodes --template '{{ range .items }}{{ .metadata.name }}{{ "\n" }}{{ end }}' | xargs -L 1 -I X bash -c 'oc get --raw /api/v1/nodes/X/proxy/metrics > /tmp/artifacts/X.metrics' ''
          oc get --raw /metrics > /tmp/artifacts/master.metrics
          set -e
        }
        trap gather EXIT

        # rosie-bot does not know how to split suite and focus
        # so we need to detect that she is doing her best and
        # help her out by parsing the input she gives
        if [[ -z "${FOCUS:-}" && "${SUITE}" =~ ^(.*)\((.*)\)$ ]]; then
          SUITE="${BASH_REMATCH[1]}"
          FOCUS="${BASH_REMATCH[2]}"
        fi
        OS_BUILD_ENV_PULL_IMAGE=true OS_BUILD_ENV_PRESERVE=_output/local/bin/linux/amd64/extended.test hack/env make build-extended-test
        OPENSHIFT_SKIP_BUILD='true' make test-extended SUITE="${SUITE}" FOCUS="${FOCUS:-}"
  post_actions:
    - type: "host_script"
      title: "gather artifacts from test cluster"
      timeout: 900
      script: |-
        trap 'exit 0' EXIT
        base_artifact_dir="$(pwd)/artifacts"
        source ./INSTANCE_PREFIX
        for instance in $( gcloud compute instances list --regexp ".*${INSTANCE_PREFIX}.*" --uri ); do
            info="$( mktemp )"
            gcloud compute instances describe "${instance}" --format json > "${info}"
            name="$( jq '.name' --raw-output "${info}" | tail -c 5 )"
            if jq '.tags.items | contains(["ocp-master"])' --exit-status "${info}"; then
                artifact_dir="${base_artifact_dir}/masters/${name}"
                mkdir -p "${artifact_dir}" "${artifact_dir}/generated" "${artifact_dir}/journals"
                gcloud compute ssh "${instance}" -- sudo journalctl --unit origin-master.service --no-pager --all --lines=all 2>&1 > "${artifact_dir}/journals/origin-master.service" || true
                gcloud compute ssh "${instance}" -- sudo journalctl --unit origin-master-api.service --no-pager --all --lines=all 2>&1 > "${artifact_dir}/journals/origin-master-api.service" || true
                gcloud compute ssh "${instance}" -- sudo journalctl --unit origin-master-controllers.service --no-pager --all --lines=all 2>&1 > "${artifact_dir}/journals/origin-master-controllers.service" || true
                gcloud compute ssh "${instance}" -- sudo journalctl --unit etcd.service          --no-pager --all --lines=all 2>&1 > "${artifact_dir}/journals/etcd.service"  || true

                gcloud compute ssh "${instance}" -- oc get --raw /metrics --config=/etc/origin/master/admin.kubeconfig 2>&1 > "${artifact_dir}/generated/master-metrics.log"  || true
            elif jq '.tags.items | contains(["ocp-node"])' --exit-status "${info}"; then
                artifact_dir="${base_artifact_dir}/nodes/${name}"
                mkdir -p "${artifact_dir}" "${artifact_dir}/generated" "${artifact_dir}/journals"
            else
                artifact_dir="${base_artifact_dir}/unknown/${name}"
                mkdir -p "${artifact_dir}" "${artifact_dir}/generated" "${artifact_dir}/journals"
            fi

            gcloud compute ssh "${instance}" -- sudo journalctl --unit origin-node.service  --no-pager --all --lines=all 2>&1 > "${artifact_dir}/journals/origin-node.service"  || true
            gcloud compute ssh "${instance}" -- sudo journalctl --unit openvswitch.service  --no-pager --all --lines=all 2>&1 > "${artifact_dir}/journals/openvswitch.service"  || true
            gcloud compute ssh "${instance}" -- sudo journalctl --unit ovs-vswitchd.service --no-pager --all --lines=all 2>&1 > "${artifact_dir}/journals/ovs-vswitchd.service"  || true
            gcloud compute ssh "${instance}" -- sudo journalctl --unit ovsdb-server.service --no-pager --all --lines=all 2>&1 > "${artifact_dir}/journals/ovsdb-server.service"  || true
            gcloud compute ssh "${instance}" -- sudo journalctl --unit docker.service       --no-pager --all --lines=all 2>&1 > "${artifact_dir}/journals/docker.service"  || true
            gcloud compute ssh "${instance}" -- sudo journalctl --unit dnsmasq.service      --no-pager --all --lines=all 2>&1 > "${artifact_dir}/journals/dnsmasq.service"  || true

            gcloud compute ssh "${instance}" -- oc get --raw /metrics --server=https://$( uname --nodename ):10250                  2>&1 > "${artifact_dir}/generated/node-metrics.log"  || true
            gcloud compute ssh "${instance}" -- "sudo docker version && sudo docker info && sudo docker images && sudo docker ps -a" 2>&1 > "${artifact_dir}/generated/docker.info"  || true
            gcloud compute ssh "${instance}" -- sudo yum history info origin                                                         2>&1 > "${artifact_dir}/generated/origin_package_history.log"  || true
            gcloud compute ssh "${instance}" -- "sudo df -h && sudo pvs && sudo vgs && sudo lvs"                                     2>&1 > "${artifact_dir}/generated/filesystem.info" || true
            gcloud compute ssh "${instance}" -- sudo yum list installed                                                              2>&1 > "${artifact_dir}/generated/installed_packages.log"  || true
            gcloud compute ssh "${instance}" -- sudo ausearch -m AVC -m SELINUX_ERR -m USER_AVC                                      2>&1 > "${artifact_dir}/generated/avc_denials.log" || true
            gcloud compute ssh "${instance}" -- sudo journalctl _PID=1 --no-pager --all --lines=all                                  2>&1 > "${artifact_dir}/generated/pid1.journal"  || true
        done
    - type: "script"
      title: "deprovision test cluster"
      repository: "release"
      timeout: 900
      script: |-
        cd cluster/test-deploy/data
        ../../bin/local.sh ansible-playbook playbooks/terminate.yaml
  artifacts:
    - "/tmp/artifacts"
