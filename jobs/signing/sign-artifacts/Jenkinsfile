#!/usr/bin/env groovy

node {
    checkout scm
    def buildlib = load("pipeline-scripts/buildlib.groovy")
    def commonlib = buildlib.commonlib
    commonlib.describeJob("sign-artifacts", """
        <h2>Sign OCP4 release image / clients and publish signatures</h2>
        <b>Timing</b>: The "release" job runs this after a release is accepted.
        Can be run manually if that fails.

        See https://github.com/openshift/art-docs/blob/master/4.y.z-stream.md#sign-the-release

        The shasum file for the clients is signed and signatures published next
        to the shasum file itself.
            http://mirror.openshift.com/pub/openshift-v4/<arch>/clients/ocp/
        The release image shasum is signed and the signature published both on
        Google Cloud Storage and mirror:
            <a href="http://mirror.openshift.com/pub/openshift-v4/signatures/openshift/" target="_blank">http://mirror.openshift.com/pub/openshift-v4/signatures/openshift/</a>
    """)


    // Expose properties for a parameterized build
    properties(
        [
            [
                $class: 'ParametersDefinitionProperty',
                parameterDefinitions: [
                    choice(
                        name: 'ARCH',
                        description: 'The architecture for this release',
                        choices: commonlib.brewArches,
                    ),
                    string(
                        name: 'NAME',
                        description: 'Release name (e.g. 4.2.0)',
                        defaultValue: "",
                        trim: true,
                    ),
                    string(
                        name: 'SIGNATURE_NAME',
                        description: 'Signature name\nStart with signature-1 and only increment if adding an additional signature to a release!',
                        defaultValue: "signature-1",
                        trim: true,
                    ),
                    choice(
                        name: 'CLIENT_TYPE',
                        description: 'Which type is it, stable (ocp) or dev (ocp-dev-preview)?',
                        choices: [
                            "ocp",
                            "ocp-dev-preview",
                        ].join("\n"),
                    ),
                    choice(
                        name: 'PRODUCT',
                        description: 'Which product to sign',
                        choices: [
                            "openshift",
                            "rhcos",
                            "coreos-installer",
                        ].join("\n"),
                    ),
                    choice(
                        name: 'ENV',
                        description: 'Which environment to sign in',
                        choices: [
                            "stage",
                            "prod",
                        ].join("\n"),
                    ),
                    choice(
                        name: 'KEY_NAME',
                        description: 'Which key to sign with\nIf ENV==stage everything becomes "test"\nFor prod we currently use "redhatrelease2"',
                        choices: [
                            "test",
                            "beta2",
                            "redhatrelease2",
                        ].join("\n"),
                    ),
                    string(
                        name: 'DIGEST',
                        description: 'The digest of the release. Example value: "sha256:f28cbabd1227352fe704a00df796a4511880174042dece96233036a10ac61639"\nCan be taken from the Release job.',
                        defaultValue: "",
                        trim: true,
                    ),
                    commonlib.dryrunParam('Only do dry run test and exit\nDoes not send anything over the bus'),
                    commonlib.mockParam(),
                ]
            ],
            disableResume()
        ]
    )

    commonlib.checkMock()
    def workDir = "${env.WORKSPACE}/working"
    buildlib.cleanWorkdir(workDir)

    // must be able to access remote registry for verification
    buildlib.registry_quay_dev_login()
    def timestamp = new Date().format("yyyyMMddHHmmss")

    def umb_timeout = 6

    stage('sign-artifacts') {
        def noop = params.DRY_RUN ? " --noop" : " "

        currentBuild.displayName += "- ${params.NAME}"
        if (params.DRY_RUN) {
            currentBuild.displayName += " (dry-run)"
            currentBuild.description = "[DRY RUN]"
        }

        if ( !env.JOB_NAME.startsWith("signing-jobs/") ) {
            requestIdSuffix = "-test"
        } else {
            requestIdSuffix = ""
        }

        def digest = commonlib.sanitizeInvisible(params.DIGEST).trim()
        def digestParam = digest ? "--digest ${digest}" : ""
        if ( digest && !(digest ==~ /sha256:[0-9a-f]{64}/) ) {
            currentBuild.description = "bad digest"
            error("The digest does not look like 'sha256:hex64'")
        }

        wrap([$class: 'BuildUser']) {
            def buildUserId = (env.BUILD_USER_ID == null) ? "automated-process" : env.BUILD_USER_ID

            if ( buildUserId == "automated-process" ) {
                echo("Automated sign request started: manually setting signing requestor")
            }

            echo("Submitting${noop} signing requests as user: ${buildUserId}")

            dir(workDir) {
                withCredentials([file(credentialsId: '0xffc054e-openshift-art-signatory.crt', variable: 'busCertificate'),
                                 file(credentialsId: '0xffc054e-openshift-art-signatory.key', variable: 'busKey')]) {
                    // ######################################################################
                    def baseUmbParams = buildlib.cleanWhitespace("""
                                --requestor "${buildUserId}" --sig-keyname ${params.KEY_NAME}
                                --release-name "${params.NAME}" --client-cert ${busCertificate}
                                --client-key ${busKey} --env ${params.ENV}
                            """)

                    if ( params.PRODUCT == 'openshift' ) {
                        // ######################################################################
                        // Does the required sha256sum.txt file exist yet?
                        def shaFile = "https://mirror.openshift.com/pub/openshift-v4/${params.ARCH}/clients/${params.CLIENT_TYPE}/${params.NAME}/sha256sum.txt"
                        try {
                            echo("Checking if required sha256sum.txt file exists")
                            httpRequest(
                                httpMode: 'HEAD',
                                responseHandle: 'NONE',
                                url: shaFile,
                            )
                        } catch (exc) {
                            echo("ERROR: Required sha256sum.txt file is missing")
                            currentBuild.description += "\nCould not submit OpenShift signing requests, the required sha256sum.txt file is missing"
                            error("Expected to find: ${shaFile} but it was missing")
                        }

                        def openshiftJsonSignParams = buildlib.cleanWhitespace("""
                             ${baseUmbParams} --product openshift --arch ${params.ARCH} --client-type ${params.CLIENT_TYPE}
                             --request-id 'openshift-json-digest-${timestamp}${requestIdSuffix}' ${digestParam} ${noop}
                         """)

                        echo "Submitting OpenShift Payload JSON claim signature request"
                        retry(3) {
                            timeout(time: umb_timeout, unit: 'MINUTES') {
                                commonlib.shell(
                                    script: "../umb_producer.py json-digest ${openshiftJsonSignParams}"
                                )
                            }
                        }

                        if ( params.ARCH == "multi" ) {
                            // Heterogeneous release payloads are manifest lists. When podman is verifying a signature
                            // it verifies the signature of an individual manifest -- not the manifest list. So
                            // we need to create signatures for each arch's manifest.
                            // This job will be invoked with ARCH=multi where the digest is a manifest list
                            // AND with the the digest is an underlying manifest.
                            // If this job is invoked with a digest for a manifest list, queue up this job
                            // again for each manifest within it.

                            quay_repo = 'ocp-release'
                            if (params.CLIENT_TYPE == 'ocp-dev-preview' && params.NAME.contains('nightly')) {
                                quay_repo = 'ocp-release-nightly'
                            }

                            oc_info_cmd = "oc image info quay.io/openshift-release-dev/${quay_repo}@${digest}"
                            // First, detect whether this is a manifest list. oc returns an error if run
                            // against a manifest list, so do no throw an exception on non-zero return code.
                            // Stderr is also used for manifest list metadata, so redirect it to stdout
                            res = commonlib.shell(script: oc_info_cmd + ' 2>&1', returnAll: true)

                            // application/vnd.docker.distribution.manifest indicates this is a single manifest
                            // and not a manifest list, so use that to determine if this is
                            if ( !res.stdout.contains('application/vnd.docker.distribution.manifest') ) {
                                // This is a manifest list OR there was an actual error (e.g. can't read image)
                                // from oc. A manifest list output should look like:
                                /*
                                  OS            DIGEST
                                  linux/amd64   sha256:58f91f37954a23aa049ff139349dfd6ac96f2cd4d35b5a0642a3f64763f04190
                                  linux/ppc64le sha256:de6360f6d38dc72abd04e0fbd3d687be612bad364569825a20076033ac9b8f0f
                                  linux/s390x   sha256:077964cc30e91b79bf1df398c6f3da0bb9746677369dc836fcb4e511f6249138
                                  linux/arm64   sha256:34b9a0c61ed38f2876b3010a12ab92d2b4abe4dd711e67f79ac522ade9abaa94

                                */
                                if ( res.stdout.contains('DIGEST') ) {
                                    for ( def oc_info_line : res.stdout.trim().split() ) {
                                        if ( oc_info_line.contains('sha256:') ) {
                                            def sha_digest = 'sha256:' + oc_info_line.split(':')[1].trim()
                                            build(
                                                    job: '/signing-jobs/signing%2Fsign-artifacts',
                                                    propagate: true,
                                                    parameters: [
                                                        string(name: 'ARCH', value: params.ARCH),
                                                        string(name: 'NAME', value: params.NAME),
                                                        string(name: 'SIGNATURE_NAME', value: params.SIGNATURE_NAME),
                                                        string(name: 'CLIENT_TYPE', value: params.CLIENT_TYPE),
                                                        string(name: 'PRODUCT', value: params.PRODUCT),
                                                        string(name: 'ENV', value: params.ENV),
                                                        string(name: 'KEY_NAME', value: params.KEY_NAME),
                                                        string(name: 'DIGEST', value: sha_digest),
                                                        booleanParam(name: 'DRY_RUN', value: params.DRY_RUN),
                                                        booleanParam(name: 'MOCK', value: params.MOCK)
                                                    ]
                                            )
                                        }
                                    }
                                } else {
                                    error("Error reading image metadata with oc: ${res.stdout}")
                                }
                            }
                        }

                        // ######################################################################

                        def openshiftSha256SignParams = buildlib.cleanWhitespace("""
                            ${baseUmbParams} --product openshift --arch ${params.ARCH} --client-type ${params.CLIENT_TYPE}
                            --request-id 'openshift-message-digest-${timestamp}${requestIdSuffix}' ${noop}
                        """)

                        echo "Submitting OpenShift sha256 message-digest signature request"
                        retry(3) {
                            timeout(time: umb_timeout, unit: 'MINUTES') {
                                commonlib.shell(
                                    script: "../umb_producer.py message-digest ${openshiftSha256SignParams}"
                                )
                            }
                        }
                    } else if ( params.PRODUCT == 'rhcos' ) {
                        def rhcosSha256SignParams = buildlib.cleanWhitespace("""
                            ${baseUmbParams} --product rhcos ${noop} --arch ${params.ARCH}
                            --request-id 'rhcos-message-digest-${timestamp}${requestIdSuffix}'
                        """)

                        echo "Submitting RHCOS sha256 message-digest signature request"
                        retry(3) {
                            timeout(time: umb_timeout, unit: 'MINUTES') {
                                res = commonlib.shell(
                                    returnAll: true,
                                    script: "../umb_producer.py message-digest ${rhcosSha256SignParams}"
                                )
                            }
                        }
                    } else if ( params.PRODUCT == 'coreos-installer' ) {
                        def coreosSha256SignParams = buildlib.cleanWhitespace("""
                                    ${baseUmbParams} --product coreos-installer ${noop} --arch ${params.ARCH}
                                    --request-id 'coreos-installer-message-digest-${timestamp}${requestIdSuffix}'
                                """)
                        echo "Submitting coreos-install sha256 message-digest signature request"
                        retry(3) {
                            timeout(time: umb_timeout, unit: 'MINUTES') {
                                commonlib.shell(
                                    script: "../umb_producer.py message-digest ${coreosSha256SignParams}"
                                )
                            }
                        }
                    }
                }
            }
        }
    }

    stage('mirror artifacts') {
        // This job mirrors two different kinds of signatures.
        //
        // 1) JSON digest claims, they are signatures for the release
        // payload, stored in a JSON format.
        //
        // 2) Message digests, they are sha256sum.txt files which have
        // sha digests for a directory of contents
        // ######################################################################

        if (params.DRY_RUN) {
            echo "Would have archived artifacts in jenkins"
            echo "Would have mirrored artifacts to mirror.openshift.com/pub/:"
        } else {
            echo "Mirroring artifacts to mirror.openshift.com/pub/"

            dir(workDir) {
                try {
                    if ( params.PRODUCT == 'openshift' ) {
                        // ######################################################################

                        // the umb producer script should have generated two
                        // files. One is a 'sha26=.......' and one is
                        // 'sha256sum.txt.gpg'

                        // sha256=...........
                        //
                        // 1) JSON digest claims. They get mirrored to
                        // mirror.openshift.com/pub/openshift-v4/ using this directory
                        // structure:
                        //
                        // signatures/openshift/release/
                        //   -> sha256=<IMAGE-DIGEST>/signature-1
                        //
                        // where <IMAGE-DIGEST> is the digest of the payload image and
                        // the signed artifact is 'signature-1'
                        //
                        // 2) A message digest (sha256sum.txt) is mirrored to
                        // https://mirror.openshift.com/pub/openshift-v4/x86_64/clients/
                        // using this directory structure:
                        //
                        // ocp/
                        //  -> <RELEASE-NAME>/sha256sum.txt.gpg
                        //
                        // where <RELEASE-NAME> is something like '4.1.0-rc.5'

                        // transform the file into a directory containing the
                        // file, mirror to google.
                        //
                        // Notes on gsutil options:
                        // -n - no clobber/overwrite
                        // -v - print url of item
                        // -L - write to log for auto re-processing
                        // -r - recursive
                        def googleStoragePath = (params.ENV == 'stage') ? 'test-1' : 'official'
                        def gsutil = '/mnt/nfs/home/jenkins/google-cloud-sdk/bin/gsutil'  // doesn't seem to be in path
                        commonlib.shell("""
                        for file in sha256=*; do
                            mv \$file ${params.SIGNATURE_NAME}
                            mkdir \$file
                            mv ${params.SIGNATURE_NAME} \$file
                            i=1
                            until ${gsutil} cp -n -v -L cp.log -r \$file gs://openshift-release/${googleStoragePath}/signatures/openshift/release; do
                                sleep 1
                                i=\$(( \$i + 1 ))
                                if [ \$i -eq 10 ]; then echo "Failed to mirror to google after 10 attempts. Giving up."; exit 1; fi
                            done
                            until ${gsutil} cp -n -v -L cp.log -r \$file gs://openshift-release/${googleStoragePath}/signatures/openshift-release-dev/ocp-release; do
                                sleep 1
                                i=\$(( \$i + 1 ))
                                if [ \$i -eq 10 ]; then echo "Failed to mirror to google after 10 attempts. Giving up."; exit 1; fi
                            done
                            until ${gsutil} cp -n -v -L cp.log -r \$file gs://openshift-release/${googleStoragePath}/signatures/openshift-release-dev/ocp-release-nightly; do
                                sleep 1
                                i=\$(( \$i + 1 ))
                                if [ \$i -eq 10 ]; then echo "Failed to mirror to google after 10 attempts. Giving up."; exit 1; fi
                            done
                        done
                        """)
                        sshagent(["openshift-bot"]) {
                            withCredentials([aws(credentialsId: 's3-art-srv-enterprise', accessKeyVariable: 'AWS_ACCESS_KEY_ID', secretKeyVariable: 'AWS_SECRET_ACCESS_KEY')]) {
                                def mirrorReleasePath = (params.ENV == 'stage') ? 'test' : 'release'
                                sh "aws s3 sync --no-progress --exact-timestamps --exclude='*' --include 'sha256=*' ./ s3://art-srv-enterprise/pub/openshift-v4/signatures/openshift/${mirrorReleasePath}/"
                                if (mirrorReleasePath == 'release') {
                                    sh "aws s3 sync --no-progress --exact-timestamps --exclude='*' --include 'sha256=*' ./ s3://art-srv-enterprise/pub/openshift-v4/signatures/openshift-release-dev/ocp-release/"

                                    sh "aws s3 sync --no-progress --exact-timestamps --exclude='*' --include 'sha256=*' ./ s3://art-srv-enterprise/pub/openshift-v4/signatures/openshift-release-dev/ocp-release-nightly/"
                                }
                            }
                        }

                        // ######################################################################

                        // sha256sum.txt.gpg
                        //
                        // For message digests (mirroring type 2) we'll see instead
                        // that .artifact_meta.type says 'message-digest'. Take this
                        // for example (request to sign the sha256sum.txt file from
                        // 4.1.0-rc.5):
                        //
                        //     "artifact_meta": {
                        //         "product": "openshift",
                        //         "release_name": "4.1.0-rc.5",
                        //         "type": "message-digest",
                        //         "name": "sha256sum.txt.gpg"
                        //     }
                        //
                        // Note that the 'product' key WILL become important when we
                        // are sending RHCOS bare metal message-digests in the
                        // future. From the .artifact_meta above we know that we have
                        // just received the sha256sum.txt.gpg file for openshift
                        // release 4.1.0-rc.5. We will mirror this file to:
                        //
                        // https://mirror.openshift.com/pub/openshift-v4/x86_64/clients/
                        //  --> ocp/
                        //  ----> `.artifacts.name`/
                        //  ------> sha256sum.txt.gpg
                        //  ==> https://mirror.openshift.com/pub/openshift-v4/x86_64/clients/ocp/4.1.0-rc.5/sha256sum.txt.gpg

                        sshagent(["openshift-bot"]) {
                            withCredentials([aws(credentialsId: 's3-art-srv-enterprise', accessKeyVariable: 'AWS_ACCESS_KEY_ID', secretKeyVariable: 'AWS_SECRET_ACCESS_KEY')]) {
                                def mirrorReleasePath = "openshift-v4/${params.ARCH}/clients/${params.CLIENT_TYPE}/${params.NAME}"
                                sh "aws s3 sync --no-progress --exact-timestamps --exclude='*' --include 'sha256sum.txt.gpg' ./ s3://art-srv-enterprise/pub/${mirrorReleasePath}/"
                            }
                        }
                    } else if ( params.PRODUCT == 'rhcos') {
                        sshagent(["openshift-bot"]) {
                            withCredentials([aws(credentialsId: 's3-art-srv-enterprise', accessKeyVariable: 'AWS_ACCESS_KEY_ID', secretKeyVariable: 'AWS_SECRET_ACCESS_KEY')]) {
                                def name_parts = params.NAME.split('\\.')
                                def nameXY = "${name_parts[0]}.${name_parts[1]}"
                                def mirrorReleasePath = "openshift-v4/${params.ARCH}/dependencies/rhcos/${nameXY}/${params.NAME}"
                                sh "aws s3 sync --no-progress --exact-timestamps --exclude='*' --include 'sha256sum.txt.gpg' ./ s3://art-srv-enterprise/pub/${mirrorReleasePath}/"
                            }
                        }
                    } else if ( params.PRODUCT == 'coreos-installer' ) {
                        sshagent(["openshift-bot"]) {
                            withCredentials([aws(credentialsId: 's3-art-srv-enterprise', accessKeyVariable: 'AWS_ACCESS_KEY_ID', secretKeyVariable: 'AWS_SECRET_ACCESS_KEY')]) {
                                sh "aws s3 sync --no-progress --exact-timestamps --exclude='*' --include 'sha256sum.txt.gpg' ./ s3://art-srv-enterprise/pub/openshift-v4/${params.ARCH}/clients/coreos-installer/${params.NAME}/"
                                sh "aws s3 sync --no-progress --exact-timestamps --exclude='*' --include 'sha256=*' ./ s3://art-srv-enterprise/pub/openshift-v4/${params.ARCH}/clients/coreos-installer/latest/"
                            }
                        }
                    }
                } finally {
                    echo "Archiving artifacts in jenkins:"
                    commonlib.safeArchiveArtifacts([
                        "working/cp.log",
                        "working/*.gpg",
                        "working/sha256=*",
                        ]
                    )
                }
            }
        }
    }

    stage('log sync'){
        buildArtifactPath = env.WORKSPACE.replaceFirst('/working/', '/builds/')
        buildArtifactPath = buildArtifactPath.split('@')[0]   // When multiple jobs are running, workspaces have a @### suffix, so trim it off it it exists
        echo "Artifact path (source to sync): ${buildArtifactPath}"
        // Find tool configuration for 'rclone' in bitwarden under
        // "ART S3 Signing Job Logs Bucket"
        //
        // Non-Obvious Option Notes:
        //   --no-traverse=Don't traverse destination file system on
        //       copy. We have a lot of files remotely, so this should
        //       speed things up.
        //   --max-age=Consider local items modified within the period given
        //   --low-level-retries 1=Don't bother retrying small
        //       failures, just do full retries
        //   --local-no-check-updated=The log we are copying for this
        //       job is constantly updating, it's ok, don't worry
        //       about it. We'll update the remote version next time
        //   --ignore-existing=We can't update s3 objects, so don't
        //       consider for syncing if they are already on the remote
        def logCopyOpts = "--verbose copy --s3-chunk-size 5M --exclude 'program.dat' --no-traverse --max-age 24h --retries-sleep 10s --ignore-existing --local-no-check-updated --low-level-retries 1 --retries 5 ${buildArtifactPath} s3SigningLogs:art-build-artifacts/signing-jobs/signing%2Fsign-artifacts/"

	sh "/bin/rclone version"

        if ( !params.DRY_RUN ) {
            sh "/bin/rclone ${logCopyOpts}"
        } else {
            echo "DRY-RUN, not syncing logs (but this would have happened):"
            echo "Artifact path (source to sync): ${buildArtifactPath}"
            sh "/bin/rclone --dry-run ${logCopyOpts}"
        }
    }

    buildlib.cleanWorkspace()
}
